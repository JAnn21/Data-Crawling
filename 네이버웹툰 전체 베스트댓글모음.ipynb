{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#월요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후기\n",
      "268화_끝나지 않은 불씨\n",
      "Loading took too much time!\n",
      "6화\n",
      "Loading took too much time!\n",
      "3부 - 90화 SHARK\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "2부 32화\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_mon = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "monday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=mon'\n",
    "\n",
    "wd.get(monday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "monday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    monday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(monday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(monday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(monday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_mon.append([comment_str.text] + [monday[i][2]] + [monday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_mon, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_mon.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 방법으로 하면 깨지지 않음!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "comment_table = pd.DataFrame(result_mon) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_monday2.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#화요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134화\n",
      "31화\n",
      "128\n",
      "29화\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "159. 순수한 의문\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_tue = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "tuesday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=tue'\n",
    "\n",
    "wd.get(tuesday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "tuesday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    tuesday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(tuesday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(tuesday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(tuesday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_tue.append([comment_str.text] + [tuesday[i][2]] + [tuesday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_tue, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_tue.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수요일 => wednesday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2부 125화\n",
      "029. Ep.07 건물주 (3)\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "321화 청약 대회 1화\n",
      "168화. 마카롱 만드는 만화 (2)\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "ROUND 85. 불협화음 (4)\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_wed = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "wednesday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=wed'\n",
    "\n",
    "wd.get(wednesday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "wednesday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    wednesday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(wednesday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(wednesday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(wednesday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_wed.append([comment_str.text] + [wednesday[i][2]] + [wednesday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_wed, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_wed.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#목요일 => thursday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329. Sunset\n",
      "46화 벽간 소음\n",
      "휴재 특별편 5화. 조금은 대충 살아도 괜찮다.\n",
      "308화 생인형 #3\n",
      "69화. 다시 만난 세계 (1)\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_thu = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "thursday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=thu'\n",
    "\n",
    "wd.get(thursday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "thursday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    thursday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(thursday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(thursday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(thursday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_thu.append([comment_str.text] + [thursday[i][2]] + [thursday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_thu, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_thu.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 금요일 => friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316화 김기명 [15]\n",
      "3화: 망설이지 말고 지금 바로\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "13화\n",
      "31화\n",
      "490화\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_fri = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "friday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=fri'\n",
    "\n",
    "wd.get(friday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "friday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    friday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(friday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(friday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(friday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_fri.append([comment_str.text] + [friday[i][2]] + [friday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_fri, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_fri.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#토요일 saturday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제364화 한태성의 집과 가족 (2)\n",
      "2부206화 흰눈썹 대 빠르1\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "168화. 마카롱 만드는 만화 (2)\n",
      "85화 : 징계위원회\n",
      "5. 힙한반등\n",
      "Loading took too much time!\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_sat = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "saturday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=sat'\n",
    "\n",
    "wd.get(saturday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "saturday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    saturday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(saturday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(saturday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(saturday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_sat.append([comment_str.text] + [saturday[i][2]] + [saturday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_sat, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_sat.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#일요일 sunday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56화 : 오 필승 코리아\n",
      "46화 벽간 소음\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "2부 72화 - 기가 VS 제 1 마왕자\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "27화\n",
      "71화\n",
      "Loading took too much time!\n",
      "Loading took too much time!\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_sun = []\n",
    "\n",
    "wd = webdriver.Chrome('C:/Users/gjkh4/CRWL_김지현/chromedriver_win32/chromedriver.exe')\n",
    "sunday_URL = 'https://comic.naver.com/webtoon/weekdayList.nhn?week=sun'\n",
    "\n",
    "wd.get(sunday_URL)\n",
    "webtoontitle_data = wd.page_source        \n",
    "soupData_webtoon = BeautifulSoup(webtoontitle_data, 'html.parser')\n",
    "title_name = soupData_webtoon.select(\"div.list_area > ul.img_list > li > dl > dt > a\") # 웹툰 순위별로 이름 받아오기\n",
    "sunday= [] # 순위별로 이름과 주소에 해당하는 값 받아오기\n",
    "for list in title_name :\n",
    "    #받아온 주소 중 필요한 부분만 떼어낸다.\n",
    "    addr_result = list.attrs['href'].split('titleId=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if addr_result =='' : # 비어있다면 다시# 만약 주소에서 titled이 가장 마지막에 위치한다면 결과값이 안나올 수 있기에 다시 한 번 else로 잡음\n",
    "        addr_result = list.attrs['href'].split('titleId=')[1]\n",
    "    sunday.append([list.text] + [addr_result] + [list.attrs['title']]) # 0번에는 웹툰클릭위한 웹툰이름, 1번에는 웹툰번호알기위한 주소, 2번은 웹툰 풀네임\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "for i in range(0,5) : # 인기순 5개만\n",
    "    wd.get(sunday_URL)\n",
    "    \n",
    "    # 저장된 웹툰이름으로 웹툰 페이지에 접속 후 그 url저장\n",
    "    wd.find_element_by_partial_link_text(sunday[i][0]).click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n",
    "    # 먼저 웹툰 들어가서 가장 최근 만화 클릭하기\n",
    "    # 휴재가 아니라면 가장 최근 웹툰이 나오기에 바로 그 페이지에서 회별 숫자를 받기 위해 title을 찾는다.\n",
    "    title_num=wd.find_elements_by_class_name('title')\n",
    "    print(title_num[0].text)\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            wd.find_element_by_partial_link_text(title_num[0].text).click() # 가장 첫 번째 회차의 이름으로 해당 페이지에 접속\n",
    "            time.sleep(10)\n",
    "            WebDriverWait(wd, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'vote_lst'))) # 클릭하고 들어갈 때까지 대기해주는 것으로 페이지에 클래스이름인 vote_lst가 나올 때까지 10정도 기다린다.\n",
    "            break\n",
    "            \n",
    "        except: # TimeoutException\n",
    "            print('Loading took too much time!')\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    recent_num_url = wd.current_url\n",
    "    \n",
    "    # 가장 최신 회차의 주소를 알아내서 거기서 회차수만 받아옴.\n",
    "    no_result = recent_num_url.split('no=')[1].split('&')[0] # 주소에서 no = 이 부분이 회차 num인데 no=과 & 사이에 숫자만 받아옴\n",
    "    if no_result =='': # 결과가 없다면\n",
    "        no_result = recent_num_url.split('no=')[1]\n",
    "            \n",
    "        \n",
    "    int_found = int(no_result)# 가장 최근 회차를 int형으로 받아옴\n",
    "\n",
    "    \n",
    "    comment_URL = 'https://comic.naver.com/comment/comment.nhn?titleId=%s' % str(sunday[i][1])\n",
    "\n",
    "    # 최신 횟차 수 만큼 반복문을 돌려서 모든 회차의 가장 먼저 나오는 베스트댓글을 긁어옴,\n",
    "    for toon_part in range(int_found, 0, -1) :\n",
    "        Webtoon_URL = comment_URL + '&no=%s' % str(toon_part)\n",
    "\n",
    "        wd.get(Webtoon_URL)\n",
    "\n",
    "        rcv_data = wd.page_source        \n",
    "        soupData = BeautifulSoup(rcv_data, 'html.parser')\n",
    "\n",
    "        # 댓글 받아오기\n",
    "        comment = soupData.findAll('span', attrs={'class': 'u_cbox_contents'})\n",
    "\n",
    "        for comment_str in comment:\n",
    "            result_sun.append([comment_str.text] + [sunday[i][2]] + [sunday[i][1]]) # 댓글과 웹툰명, 웹툰번호를 받음.\n",
    "            \n",
    "            \n",
    "comment_table = pd.DataFrame(result_sun, columns=('comment', 'webtoon_name', 'webtoon_num')) # 데이터프레임을 만듦\n",
    "comment_table.to_csv(\"./comment_sun.csv\", mode='w', encoding='utf-8-sig')\n",
    "#del result_mon[:]\n",
    "print('FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
